### CNN 卷積神經網絡

- **卷積提取特征，池化壓縮特征**：
  - 卷積層：通過加權提取特征。
  - 池化層：壓縮特征，降低數據維度。

#### 卷積層

- **卷積神經網絡的學習過程**：

  - 這是一個尋找最優權重參數的過程。
  - 將圖像分成小區域，對每個區域進行加權以生成特征圖。每個特征圖的每個元素是相應位置卷積的結果。

- **特征提取過程**：

  - 假設輸入圖像大小為 `32 × 32 × 3`，其中 `3` 表示 RGB 三個顏色通道。對每個顏色通道進行卷積，然後將結果相加。
  - 使用卷積核（filter）的權重參數進行特征提取。卷積操作通過內積（對應位置相乘）計算，並加上一個偏置項（Bias `b0`）。
  - 不同的特征矩陣（規格相同）會生成不同的特征圖。每次卷積選擇的卷積核是一致的，這樣會得到多個特征圖，稱為特征圖的深度。

- **卷積層涉及參數**：

  - **滑動窗口步長**：移動步長決定了特征圖的大小，常見步長為 1。
  - **卷積核尺寸**：選擇區域的大小，例如 `3 × 3`。
  - **邊緣填充（Zero Padding）**：在圖像邊界加上一圈 0 來彌補邊界特征缺失。
  - **卷積核個數**：最終生成的特征圖數量，每個卷積核生成一個特征圖。

- **卷積參數共享**：
  - 使用相同的卷積核對圖像中的每個區域進行特征提取。

#### 池化層

- **特征壓縮**：
  - 池化層對特征圖進行壓縮（下采樣），選擇重要的特征，丟棄不重要的特征。這樣只會縮減特征圖的長和寬，而不改變深度。
  - 池化層不涉及矩陣計算，僅篩選特征圖中的最大值或平均值等。

#### 卷積神經網絡的框架

- 每次卷積結束後，需要進行非線性變換（如激活函數）。
- 經過幾次卷積後，對特征圖進行池化操作，最後將特征圖轉化為分類概率值（全連接層）。

- **全連接層**：
  - 由於全連接層的參數不能為三維，需要將處理後的特征圖拉成一個一維特征向量，轉化為分類的概率值。

#### VGG 網絡

- 卷積核大小為 `3 × 3`，經過池化層後會損失一些信息。在下一次卷積過程中，用特征圖的個數來彌補長寬的損失。

#### ResNet 殘差網絡

- 層數越多並不一定越好，過多的層數可能會引入不良影響，需要設計方案來進行剔除。
- **殘差學習**：經過卷積層後，如果學得不好，可以通過學習原始特徵的殘差來改善。這樣即使之前的學習不佳，也可以用來提高效果。

#### 感受野

- **感受野**：指當前值由前面多少個值參與計算得到的結果。希望感受野越大越好。
- 三個 `3 × 3` 卷積層所需的參數比一個大卷積層要少，實際效率更高。

- **計算速度**：
  - 計算速度與參數個數有關。卷積層數量越多，特征提取越細膩，非線性變換越多，計算開銷也會增加。
