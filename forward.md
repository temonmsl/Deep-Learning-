# 為何需要 `forward`

在 PyTorch 中，`forward` 方法是自定義神經網絡模型時必須實現的一個核心方法，它定義了模型的前向傳播過程（Forward Propagation）。當你調用模型對象時（如 `output = model(input)`），實際是調用了 `forward` 方法。因此，**`forward` 是定義模型如何處理輸入數據並輸出結果的關鍵**。

## 主要原因與作用

### 1. 定義模型的前向傳播過程
`forward` 方法指定了輸入數據是如何通過神經網絡的各層流動的，也就是定義了從輸入到輸出的計算路徑。例如，輸入經過卷積層、池化層、全連接層等，最終得到輸出。

```python
def forward(self, input):
    output = self.linear1(input)  # 通過線性層
    return output
```

在這個方法中，輸入數據 `input` 會經過網絡的各層處理，最終輸出預測結果 `output`。

## 2. 保證靈活性與可定制性

`forward` 方法允許你自由地定義輸入數據如何流經模型的各層。這給你很大的靈活性，可以根據任務需要，自由設計模型結構、層與層之間的關系、數據變換等。

## 3. 與 `backward` 共同作用

在神經網絡的訓練中，有兩個關鍵步驟：前向傳播（`forward`）和反向傳播（`backward`）。前向傳播通過 `forward` 方法定義輸入如何變成輸出，而反向傳播會根據前向傳播中的結果來計算梯度，以更新模型的參數。PyTorch 會自動處理 `backward`，但你需要自己定義 `forward`。

## 4. 簡化代碼結構

使用 `forward` 使得神經網絡類變得更加整潔，調用模型時無需手動調用 `forward` 方法，直接使用模型對象就可以觸發前向傳播：
